{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity Identification through Screen Text Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries and Modules\n",
    "This section imports all necessary libraries and modules for file handling, image processing, data analysis and machine learning.\n",
    "- **System and file handling**: handles system operations and file management.\n",
    "- **Image processing**: facilitates image processing for feature extraction and visualization task.\n",
    "- **Data processing**: used for UI log manipulation, data operations, and analysis.\n",
    "- **Machine Learning**: tools for the clustering algorithm.\n",
    "- **CLIP**: pre-trained model from OpenAI and other feature extraction related imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System and file handling\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import gc\n",
    "\n",
    "# Image processing and visualization\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# CLIP\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel, CLIPTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading UI Log\n",
    "Loads the UI log file for processing and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ui_log_as_dataframe(log_path):\n",
    "    \"\"\"\n",
    "    Reads the UI log file into a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(log_path, sep=\";\")  # , index_col=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction from Images and Text\n",
    "This section includes functions to extract and combine features from images and text using the CLIP model and hashing techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_images_with_tokenizer(df, image_col, text_col, image_weight, text_weight, img_dir, log_root, header_txt, text_path_col=\"header_txt\"):\n",
    "    \"\"\"\n",
    "    Extracts and combines features from images and text using the CLIP model and tokenizer.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): dataframe containing the data.\n",
    "    image_col (str): column name for image paths.\n",
    "    text_col (str): column name for browser's tab text.\n",
    "    image_weight (float): weight for image features.\n",
    "    text_weight (float): weight for text features.\n",
    "    img_dir (str): directory containing the images.\n",
    "    log_root (str): root directory for logs.\n",
    "    header_txt (bool): flag to determine if all on-screen text should be used.\n",
    "    text_path_col (str): column name for ocr file paths (default is \"header_txt\").\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: dataframe with combined features.\n",
    "    \"\"\"\n",
    "    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "    combined_features = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if header_txt:\n",
    "            txt_path = os.path.join(log_root, \"ocr_results\", row[text_path_col])\n",
    "            if not os.path.exists(txt_path):\n",
    "                raise FileNotFoundError(f\"Text file does not exist in: {txt_path}\")\n",
    "            with open(txt_path, 'r') as file:\n",
    "                text = file.read()\n",
    "        else:\n",
    "            text = row[text_col]\n",
    "        input_ids = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "\n",
    "        image_path = os.path.join(img_dir, row[image_col])\n",
    "        if not os.path.exists(image_path):\n",
    "            raise ValueError(f\"Image does not exist in: {image_path}\")\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        image_inputs = processor(images=[image], return_tensors=\"pt\")\n",
    "\n",
    "        inputs = {'input_ids': input_ids['input_ids'], 'attention_mask': input_ids['attention_mask'], 'pixel_values': image_inputs['pixel_values']}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        image_features = outputs.image_embeds.cpu().numpy().flatten() * image_weight\n",
    "        text_features = outputs.text_embeds.cpu().numpy().flatten() * text_weight\n",
    "        combined_feature = np.hstack((image_features, text_features))\n",
    "        combined_features.append(combined_feature)\n",
    "\n",
    "    df['combined_features'] = combined_features\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hash(df,img_dir,image_col):\n",
    "    \"\"\"\n",
    "    Extracts hash features from images using the wavelet hash method.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): dataframe containing the data.\n",
    "    img_dir (str): directory containing the images.\n",
    "    image_col (str): column name for image paths.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: dataframe with hash features.\n",
    "    \"\"\"\n",
    "    combined_features = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        img3 = Image.open(os.path.join(img_dir, row[image_col]))\n",
    "        image_three_hash = imagehash.whash(img3)\n",
    "        combined_features.append(np.array(image_three_hash.hash).flatten())\n",
    "    \n",
    "    df['combined_features'] = combined_features\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Clustering\n",
    "This section includes a function to perform clustering on the extracted features from images and text. It uses agglomerative clustering to group similar images based on the provided range of cluster numbers and evaluates the clustering performance using various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_images(df, n_clusters_range, use_pca, n_components):\n",
    "    \"\"\"\n",
    "    Performs clustering on the features and evaluates the clustering results.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): dataframe containing the combined features.\n",
    "    n_clusters_range (tuple): range of cluster numbers to evaluate.\n",
    "    use_pca (bool): whether to apply PCA for dimensionality reduction.\n",
    "    n_components (int): number of components to keep if PCA is applied.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: dataframe with the assigned cluster labels.\n",
    "    dict: dictionary containing clustering scores for different numbers of clusters.\n",
    "    int: optimal number of clusters based on silhouette score.\n",
    "    dict: optimal clustering metrics (Silhouette score, Davies-Bouldin score, Calinski-Harabasz score).\n",
    "    \"\"\"\n",
    "        \n",
    "    features = np.array(df['combined_features'].tolist())\n",
    "    \n",
    "    if use_pca:\n",
    "        pca = PCA(n_components=n_components)\n",
    "        features = pca.fit_transform(features)\n",
    "\n",
    "    clustering_scores = {\n",
    "        'n_clusters': [],\n",
    "        'silhouette_score': [],\n",
    "        'davies_bouldin_score': [],\n",
    "        'calinski_harabasz_score': []\n",
    "    }\n",
    "\n",
    "    for k in range(*n_clusters_range):\n",
    "        clustering = AgglomerativeClustering(n_clusters=k).fit(features)\n",
    "        labels = clustering.labels_\n",
    "\n",
    "        clustering_scores['n_clusters'].append(k)\n",
    "        clustering_scores['silhouette_score'].append(silhouette_score(features, labels))\n",
    "        clustering_scores['davies_bouldin_score'].append(davies_bouldin_score(features, labels))\n",
    "        clustering_scores['calinski_harabasz_score'].append(calinski_harabasz_score(features, labels))\n",
    "\n",
    "    optimal_index = np.argmax(clustering_scores['silhouette_score'])\n",
    "    optimal_clusters = clustering_scores['n_clusters'][optimal_index]\n",
    "\n",
    "    best_clustering = AgglomerativeClustering(n_clusters=optimal_clusters).fit(features)\n",
    "    df['activity_label'] = best_clustering.labels_\n",
    "\n",
    "    optimal_metrics = {\n",
    "        'silhouette_score': clustering_scores['silhouette_score'][optimal_index],\n",
    "        'davies_bouldin_score': clustering_scores['davies_bouldin_score'][optimal_index],\n",
    "        'calinski_harabasz_score': clustering_scores['calinski_harabasz_score'][optimal_index]\n",
    "    }\n",
    "\n",
    "    return df, clustering_scores, optimal_clusters, optimal_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration Settings for UI logs\n",
    "This section defines configuration settings for various log paths, image directories, and columns. These configurations are used to set up the environment for processing different sets of UI logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1 - Invoice Resolution - Customer details with ID\n",
    "log_root = 'logs/invoice_def'\n",
    "log_path = 'logs/invoice_def/log.csv'\n",
    "image_col = 'screenshot'\n",
    "image_dir = 'resources/invoice_def'\n",
    "text_col = 'header'\n",
    "timestamp_col = 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2 - Invoice Resolution - Customer details generalized\n",
    "log_root = 'logs/invoice_def_customer_view'\n",
    "log_path = 'logs/invoice_def/log_customer_view.csv'\n",
    "image_col = 'screenshot'\n",
    "image_dir = 'resources/invoice_def_customer_view'\n",
    "text_col = 'header'\n",
    "timestamp_col = 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 3 - Payment Notification - Single User recording\n",
    "log_root = 'logs/SC50_Rebuild'\n",
    "log_path = 'logs/SC50_Rebuild/log.csv'\n",
    "image_col = 'screenshot'\n",
    "image_dir = 'resources/SC50_Rebuild'\n",
    "text_col = 'header'\n",
    "timestamp_col = 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 4 - Payment Notification - Multi-user recording\n",
    "log_root = 'logs/SC50_Rebuild'\n",
    "log_path = 'logs/SC50_Rebuild/log.csv'\n",
    "image_col = 'screenshot'\n",
    "image_dir = 'resources/SC50_Hybrid'\n",
    "text_col = 'header'\n",
    "timestamp_col = 'timestamp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary Functions for Execution\n",
    "This section includes auxiliary functions used in executions. These functions handle tasks such as overwriting CSV files, moving files, clearing caches, loading fresh data, and calculating the accuracy of clustering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overwrite_csv(df, file_path):\n",
    "    \"\"\"\n",
    "    Overwrites an existing CSV file with the DataFrame content.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): dataframe to be saved.\n",
    "    file_path (str): path where the CSV file will be saved.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "        df.to_csv(file_path, index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing CSV file: {e}\")\n",
    "\n",
    "def move_and_overwrite(source, destination):\n",
    "    \"\"\"\n",
    "    Moves a file from source to destination, overwriting the destination file if it exists.\n",
    "\n",
    "    Parameters:\n",
    "    source (str): Path of the source file.\n",
    "    destination (str): Path of the destination file.\n",
    "\n",
    "    \"\"\"\n",
    "    if os.path.exists(destination):\n",
    "        os.remove(destination)\n",
    "    shutil.move(source, destination)\n",
    "    \n",
    "def clear_caches():\n",
    "    \"\"\"\n",
    "    Clears the garbage collector and CUDA cache if available.\n",
    "    \"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def load_fresh_data():\n",
    "    \"\"\"\n",
    "    Reads and returns the UI log as a DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: dataframe containing the UI log data.\n",
    "\n",
    "    \"\"\"\n",
    "    return read_ui_log_as_dataframe(log_path)\n",
    "\n",
    "def accuracy_calculation(df, activity_label, ground_truth_colname='ground_truth'):\n",
    "    \"\"\"\n",
    "    Calculates precision, recall, and F1-score for the clustering results based on the ground truth labels.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): dataframe containing the data with predicted and ground truth labels.\n",
    "    activity_label (str): column name for predicted activity labels.\n",
    "    ground_truth_colname (str): column name for ground truth labels (default is 'ground_truth').\n",
    "\n",
    "    Returns:\n",
    "    tuple: F1-score, precision, and recall for the clustering results.\n",
    "\n",
    "    \"\"\"\n",
    "    predicted_clusters = df[activity_label].unique()\n",
    "    true_clusters = df[ground_truth_colname].unique()\n",
    "\n",
    "    cost_matrix = np.zeros((len(predicted_clusters), len(true_clusters)))\n",
    "\n",
    "    for i, pred_cluster in enumerate(predicted_clusters):\n",
    "        for j, true_cluster in enumerate(true_clusters):\n",
    "            cost_matrix[i, j] = -((df[activity_label] == pred_cluster) & (df[ground_truth_colname] == true_cluster)).sum()\n",
    "\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    cluster_mapping = {predicted_clusters[row]: true_clusters[col] for row, col in zip(row_ind, col_ind)}\n",
    "\n",
    "    df['mapped_prediction'] = df[activity_label].map(cluster_mapping)\n",
    "    df['mapped_prediction'] = df['mapped_prediction'].fillna(-1)\n",
    "\n",
    "    precision = precision_score(df[ground_truth_colname], df['mapped_prediction'], average='macro', zero_division=0)\n",
    "    recall = recall_score(df[ground_truth_colname], df['mapped_prediction'], average='macro', zero_division=0)\n",
    "    f1 = f1_score(df[ground_truth_colname], df['mapped_prediction'], average='macro', zero_division=0)\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-score: {f1}\")\n",
    "\n",
    "    return f1, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute and Save Run\n",
    "This section sets up initial configurations and parameters, runs multiple executions with different weights for image and text features, and saves the results for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'clip'\n",
    "n_clusters_range = (2, 11)\n",
    "n_components = 0.95\n",
    "use_pca = False\n",
    "tokenize = True # Always True\n",
    "header_txt = True # Should we use the full text?\n",
    "use_hash = False # Should we use hash?\n",
    "\n",
    "# Select directory to save results\n",
    "ground_truth_colname='ground_truth'\n",
    "case_study_name = \"invoice_full\" \n",
    "root_dir = os.path.join(\"executions\", case_study_name)\n",
    "os.makedirs(root_dir, exist_ok=True)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Configuration per execution\n",
    "executions = [\n",
    "    {'exec': 1, 'image_weight': 1, 'text_weight': 0},\n",
    "    {'exec': 2, 'image_weight': 0.8, 'text_weight': 0.2},\n",
    "    {'exec': 3, 'image_weight': 0.6, 'text_weight': 0.4},\n",
    "    {'exec': 4, 'image_weight': 0.5, 'text_weight': 0.5},\n",
    "    {'exec': 5, 'image_weight': 0.4, 'text_weight': 0.6},\n",
    "    {'exec': 6, 'image_weight': 0.2, 'text_weight': 0.8},\n",
    "    {'exec': 7, 'image_weight': 0, 'text_weight': 1}\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exec in executions:\n",
    "    #Load de the UI log data into a DataFrame\n",
    "    df = read_ui_log_as_dataframe(log_path)\n",
    "    clear_caches()  \n",
    "\n",
    "    # Set random seeds for reproducibility\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "\n",
    "    # Create directory for the current execution   \n",
    "    exec_dir = f\"{case_study_name}_{exec['image_weight']}_{exec['text_weight']}\"\n",
    "    exec_path = os.path.join(root_dir, exec_dir)\n",
    "    os.makedirs(exec_path, exist_ok=True)\n",
    "\n",
    "     # Set image and text weights\n",
    "    image_weight = exec['image_weight']\n",
    "    text_weight = exec['text_weight']\n",
    "    \n",
    "    # Extract features using CLIP or hash\n",
    "    if tokenize:\n",
    "        df = extract_features_from_images_with_tokenizer(df, image_col, text_col, image_weight, text_weight, image_dir, log_root, header_txt, text_path_col='header_txt')\n",
    "    elif use_hash:\n",
    "        df = extract_hash(df, image_dir, image_col)\n",
    "\n",
    "    # Perform clustering on the features\n",
    "    df, clustering_scores, optimal_clusters, optimal_metrics = cluster_images(df, n_clusters_range, use_pca, n_components)\n",
    "\n",
    "    # Calculate accuracy metrics for the clustering\n",
    "    f1, precision, recall = accuracy_calculation(df, 'activity_label', ground_truth_colname)\n",
    "\n",
    "    # Save the DataFrame with clustering results to CSV\n",
    "    df.to_csv(os.path.join(exec_path, 'df.csv'), index=False)\n",
    "\n",
    "    # Append the results of the current execution\n",
    "    results.append({\n",
    "        'exec': exec['exec'],\n",
    "        'image_weight': image_weight,\n",
    "        'text_weight': text_weight,\n",
    "        'Silhouette': optimal_metrics['silhouette_score'],\n",
    "        'Davies-Bouldin': optimal_metrics['davies_bouldin_score'],\n",
    "        'Calinski-Harabasz': optimal_metrics['calinski_harabasz_score'],\n",
    "        'F1-Score': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "    })\n",
    "\n",
    "# Save all execution results to a CSV file\n",
    "results_df = pd.DataFrame(results)\n",
    "overwrite_csv(results_df, os.path.join(root_dir, 'resultados.csv'))\n",
    "\n",
    "# Save all execution results to a CSV file\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
