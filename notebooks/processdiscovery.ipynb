{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLIP Process Discovery Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import GridBox, Layout\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# TensorFlow related imports\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# PM4Py related imports\n",
    "import pm4py\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "from pm4py.objects.conversion.process_tree import converter as pt_converter\n",
    "from pm4py.visualization.petri_net import visualizer as pn_visualizer\n",
    "from pm4py.visualization.bpmn import visualizer as bpmn_visualizer\n",
    "from pm4py.objects.bpmn.exporter import exporter as bpmn_exporter\n",
    "from pm4py.algo.evaluation.replay_fitness import algorithm as replay_fitness_evaluator\n",
    "from pm4py.algo.evaluation.precision import algorithm as precision_evaluator\n",
    "from pm4py.algo.evaluation.generalization import algorithm as generalization_evaluator\n",
    "from pm4py.algo.evaluation.simplicity import algorithm as simplicity_evaluator\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura fichero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ui_log_as_dataframe(log_path):\n",
    "  return pd.read_csv(log_path, sep=\";\")#, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminos_apriori = ((1, 0, 3, 2, 8, 4),  \n",
    "    (1, 0, 3, 2, 9),     \n",
    "    (1, 0, 3, 2, 6),     \n",
    "    (1, 0, 3, 2, 7))\n",
    "caminos_apriori_series = pd.Series(list(caminos_apriori))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_images(df, image_col, text_col, image_weight, text_weight, img_dir):\n",
    "    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "    combined_features = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        text = row[text_col]\n",
    "        # Usa os.path.join para construir la ruta completa de la imagen.\n",
    "        image_path = os.path.join(img_dir, row[image_col])\n",
    "        \n",
    "        # Asegúrate de que la imagen exista, de lo contrario lanza un error.\n",
    "        if not os.path.exists(image_path):\n",
    "            raise ValueError(f\"La imagen no existe en {image_path}\")\n",
    "\n",
    "        # Abre la imagen usando la ruta completa.\n",
    "        image = Image.open(image_path)\n",
    "        inputs = processor(text=[text], images=image, return_tensors=\"pt\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        image_features = outputs.image_embeds.cpu().numpy().flatten() * image_weight\n",
    "        text_features = outputs.text_embeds.cpu().numpy().flatten() * text_weight\n",
    "        \n",
    "        combined_feature = np.hstack((image_features, text_features))\n",
    "        combined_features.append(combined_feature)\n",
    "\n",
    "    df['combined_features'] = combined_features\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_VGG(df, root_path, image_col):\n",
    "    vgg_model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "    def extract_features(img_path):\n",
    "        if not os.path.exists(img_path):\n",
    "            raise ValueError(f\"La imagen no existe en {img_path}\")\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if img is None:\n",
    "            raise ValueError(f\"No se pudo leer la imagen: {img_path}\")\n",
    "\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        return vgg_model.predict(img).flatten()\n",
    "\n",
    "    df['combined_features'] = df[image_col].apply(lambda x: extract_features(os.path.join(root_path, x)))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_andres(df,img_dir,image_col):\n",
    "    combined_features = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        img3 = Image.open(os.path.join(img_dir, row[image_col]))\n",
    "        image_three_hash = imagehash.whash(img3)\n",
    "        combined_features.append(np.array(image_three_hash.hash).flatten())\n",
    "    \n",
    "    df['combined_features'] = combined_features\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_images(df, n_clusters_range, use_pca, n_components):\n",
    "    features = np.array(df['combined_features'].tolist())\n",
    "    \n",
    "    if use_pca:\n",
    "        pca = PCA(n_components=n_components)\n",
    "        features = pca.fit_transform(features)\n",
    "        print(f\"PCA aplicado: {features.shape[1]} componentes retenidos\")\n",
    "\n",
    "    clustering_scores = {\n",
    "        'n_clusters': [],\n",
    "        'silhouette_score': [],\n",
    "        'davies_bouldin_score': [],\n",
    "        'calinski_harabasz_score': []\n",
    "    }\n",
    "\n",
    "    for k in range(*n_clusters_range):\n",
    "        clustering = AgglomerativeClustering(n_clusters=k).fit(features)\n",
    "        labels = clustering.labels_\n",
    "\n",
    "        clustering_scores['n_clusters'].append(k)\n",
    "        clustering_scores['silhouette_score'].append(silhouette_score(features, labels))\n",
    "        clustering_scores['davies_bouldin_score'].append(davies_bouldin_score(features, labels))\n",
    "        clustering_scores['calinski_harabasz_score'].append(calinski_harabasz_score(features, labels))\n",
    "\n",
    "    # Encuentra el índice del número óptimo de clústeres basado en la mejor puntuación Silhouette\n",
    "    optimal_index = np.argmax(clustering_scores['silhouette_score'])\n",
    "    optimal_clusters = clustering_scores['n_clusters'][optimal_index]\n",
    "\n",
    "    # Ejecutar el clustering con el número óptimo de clústeres\n",
    "    best_clustering = AgglomerativeClustering(n_clusters=optimal_clusters).fit(features)\n",
    "    df['activity_label'] = best_clustering.labels_\n",
    "\n",
    "    # Obtener las métricas para el número óptimo de clústeres\n",
    "    optimal_metrics = {\n",
    "        'silhouette_score': clustering_scores['silhouette_score'][optimal_index],\n",
    "        'davies_bouldin_score': clustering_scores['davies_bouldin_score'][optimal_index],\n",
    "        'calinski_harabasz_score': clustering_scores['calinski_harabasz_score'][optimal_index]\n",
    "    }\n",
    "\n",
    "    return df, clustering_scores, optimal_clusters, optimal_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_centroides(features, labels):\n",
    "    unique_labels = np.unique(labels)\n",
    "    centroides = np.array([features[labels == label].mean(axis=0) for label in unique_labels])\n",
    "    return centroides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def reasignar_clusters_en_df(df, centroides_referencia):\n",
    "    features = np.array(df['combined_features'].tolist())\n",
    "    labels = df['activity_label'].values\n",
    "    centroides_actuales = calcular_centroides(features, labels)\n",
    "    mapeo = {}\n",
    "\n",
    "    for i, centroide_actual in enumerate(centroides_actuales):\n",
    "        similitudes = pairwise_distances([centroide_actual], centroides_referencia, metric='euclidean')\n",
    "        indice_mas_cercano = np.argmin(similitudes)\n",
    "        mapeo[i] = indice_mas_cercano\n",
    "    \n",
    "    df['activity_label'] = [mapeo[label] for label in labels]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clustering_scores(clustering_scores):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Silhouette Score\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(clustering_scores['n_clusters'], clustering_scores['silhouette_score'], marker='o')\n",
    "    plt.title('Silhouette Score')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Score')\n",
    "\n",
    "    # Davies-Bouldin Score\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(clustering_scores['n_clusters'], clustering_scores['davies_bouldin_score'], marker='o', color='red')\n",
    "    plt.title('Davies-Bouldin Score')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Score')\n",
    "\n",
    "    # Calinski-Harabasz Score\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(clustering_scores['n_clusters'], clustering_scores['calinski_harabasz_score'], marker='o', color='green')\n",
    "    plt.title('Calinski-Harabasz Score')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Score')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/clustering_scores.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_caminos(df):\n",
    "    caminos = df.groupby('process_id')['activity_label'].apply(tuple)\n",
    "    return caminos\n",
    "\n",
    "def calcular_metricas(caminos_logs, caminos_apriori, caminos_inicial, caminos_final):\n",
    "    caminos_logs_set = set(caminos_logs)\n",
    "    caminos_apriori_set = set(caminos_apriori)\n",
    "    caminos_inicial_set = set(caminos_inicial)\n",
    "    caminos_final_set = set(caminos_final)\n",
    "    \n",
    "    # Calcular las métricas\n",
    "    num_paths_apriori = len(caminos_apriori_set)\n",
    "    num_paths_inicial = len(caminos_inicial_set)\n",
    "    num_paths_final = len(caminos_final_set)\n",
    "    \n",
    "    # Porcentajes de nuevos caminos y caminos no descubiertos\n",
    "    new_paths = caminos_final_set - caminos_apriori_set\n",
    "    percent_new = len(new_paths) / num_paths_final if num_paths_final else 0\n",
    "    \n",
    "    non_discovered_paths = caminos_apriori_set - caminos_final_set\n",
    "    percent_non_discovered = len(non_discovered_paths) / num_paths_apriori if num_paths_apriori else 0\n",
    "    \n",
    "    return {\n",
    "        'num_paths_apriori': num_paths_apriori,\n",
    "        'num_paths_inicial': num_paths_inicial,\n",
    "        'num_paths_final': num_paths_final,\n",
    "        'percent_new': percent_new * 100,\n",
    "        'percent_non_discovered': percent_non_discovered * 100\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case id allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_process_id_assignment(df):\n",
    "    activity_inicial = df['activity_label'].iloc[0]\n",
    "    process_id = 1\n",
    "    process_ids = [process_id]  \n",
    "    for index, row in df.iterrows():\n",
    "        if index != 0:  \n",
    "            if row['activity_label'] == activity_inicial:\n",
    "                process_id += 1\n",
    "            process_ids.append(process_id)\n",
    "        else:\n",
    "            continue\n",
    "    df['process_id'] = process_ids\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_acciones_duplicadas(df, columna_label='activity_label'):\n",
    "    mascaras_para_eliminar = df[columna_label].eq(df[columna_label].shift())\n",
    "    df_limpio = df[~mascaras_para_eliminar]\n",
    "    \n",
    "    return df_limpio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bpmn / Petrinet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def petri_net_process(df, timestamp_col):\n",
    "    # DataFrame To EventLog\n",
    "    formatted_df = pm4py.format_dataframe(df, case_id='process_id', activity_key='activity_label', timestamp_key=timestamp_col)\n",
    "    event_log = pm4py.convert_to_event_log(formatted_df)\n",
    "\n",
    "    # Descubrimiento del árbol del proceso\n",
    "    process_tree = inductive_miner.apply(event_log)\n",
    "    net, initial_marking, final_marking = pm4py.convert_to_petri_net(process_tree)\n",
    "\n",
    "    # Métricas\n",
    "    fitness = replay_fitness_evaluator.apply(event_log, net, initial_marking, final_marking)\n",
    "    precision = precision_evaluator.apply(event_log, net, initial_marking, final_marking)\n",
    "    generalization = generalization_evaluator.apply(event_log, net, initial_marking, final_marking)\n",
    "    simplicity = simplicity_evaluator.apply(net)\n",
    "\n",
    "    # Guardar resultados\n",
    "    dot = pn_visualizer.apply(net, initial_marking, final_marking)\n",
    "    dot_path = os.path.join('results', 'pn.dot')\n",
    "    with open(dot_path, 'w') as f:\n",
    "        f.write(dot.source)\n",
    "\n",
    "    return fitness, precision, generalization, simplicity\n",
    "\n",
    "def bpmn_process(df, timestamp_col):\n",
    "    # DataFrame To EventLog\n",
    "    formatted_df = pm4py.format_dataframe(df, case_id='process_id', activity_key='activity_label', timestamp_key=timestamp_col)\n",
    "    event_log = pm4py.convert_to_event_log(formatted_df)\n",
    "\n",
    "    # Descubrimiento del modelo BPMN\n",
    "    bpmn_model = pm4py.discover_bpmn_inductive(event_log)\n",
    "\n",
    "    # Guardar resultados\n",
    "    dot = bpmn_visualizer.apply(bpmn_model)\n",
    "    dot_path = os.path.join('results', 'bpmn.dot')\n",
    "    with open(dot_path, 'w') as f:\n",
    "        f.write(dot.source)\n",
    "    bpmn_exporter.apply(bpmn_model, os.path.join('results', 'bpmn.bpmn'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nano configuration\n",
    "log_path = 'logs/Nano_logs/log.csv'\n",
    "image_col = 'ocel:screenshot:name'\n",
    "image_dir = 'resources/Nano'\n",
    "text_col = 'header'\n",
    "timestap_col = 'ocel:timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc_50 configuration\n",
    "log_path = 'logs/sice50_logs/log_m.csv'\n",
    "image_col = 'Screenshot'\n",
    "image_dir = 'resources/sc_0_size50_Balanced'\n",
    "text_col = 'header'\n",
    "timestamp_col = 'Timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoice_logs\n",
    "log_path = 'logs/invoice_logs/log_csv.csv'\n",
    "image_col = 'screenshot'\n",
    "image_dir = 'resources/invoice_management'\n",
    "text_col = 'header'\n",
    "timestamp_col = 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoice no-loop\n",
    "log_path = 'logs/invoice_logs - no loop/log_csv.csv'\n",
    "image_col = 'screenshot'\n",
    "image_dir = 'resources/invoice - no loop'\n",
    "text_col = 'header'\n",
    "timestamp_col = 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoice def (+1 path 'customer path')\n",
    "log_path = 'logs/invoice_def/log.csv'\n",
    "image_col = 'screenshot'\n",
    "image_dir = 'resources/invoice_def'\n",
    "text_col = 'header'\n",
    "timestamp_col = 'timestamp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'clip' #clip or vgg\n",
    "text_weight = 0.5\n",
    "image_weight = 0.5\n",
    "use_pca = False\n",
    "n_clusters_range = (2, 11)\n",
    "n_components = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_ui_log_as_dataframe(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_features_andres(df, image_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "extract_features_from_images() missing 1 required positional argument: 'img_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features_from_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvgg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      4\u001b[0m     df \u001b[38;5;241m=\u001b[39m extract_features_from_VGG(df, image_dir, image_col)\n",
      "\u001b[1;31mTypeError\u001b[0m: extract_features_from_images() missing 1 required positional argument: 'img_dir'"
     ]
    }
   ],
   "source": [
    "if model == 'clip':\n",
    "    df = extract_features_from_images(df, image_col, text_col, image_weight, text_weight)\n",
    "elif model == 'vgg':\n",
    "    df = extract_features_from_VGG(df, image_dir, image_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, clustering_scores, optimal_cluster, optimal_metrics = cluster_images(df, n_clusters_range, use_pca, n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLO EJECUTAR SI SE QUIERE RECALCULAR LOS CENTROIDES DE REFERENCIA\n",
    "centroides_referencia = calcular_centroides(np.array(df['combined_features']), df['activity_label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 1024)\n"
     ]
    }
   ],
   "source": [
    "X = np.stack(df['combined_features'].values)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'centroides_referencia' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcentroides_referencia\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'centroides_referencia' is not defined"
     ]
    }
   ],
   "source": [
    "print(centroides_referencia.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasignar_clusters_en_df(df, centroides_referencia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_clustering_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_clustering_scores\u001b[49m(clustering_scores)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_clustering_scores' is not defined"
     ]
    }
   ],
   "source": [
    "plot_clustering_scores(clustering_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = auto_process_id_assignment(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminos_inicial = extraer_caminos(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = eliminar_acciones_duplicadas(df, columna_label='activity_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24ca8e8aa604dc78d8e4b0732216114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7491fffc523646abb695d8fd880d4f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "computing precision with alignments, completed variants ::   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f901f195984134b75c1594986123ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fitness, precision, generalization, simplicity = petri_net_process(df)\n",
    "bpmn_process(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocel:screenshot:name</th>\n",
       "      <th>header</th>\n",
       "      <th>activity_label</th>\n",
       "      <th>process_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>screenshot0004.JPEG</td>\n",
       "      <td>LOPE</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>screenshot0005.JPEG</td>\n",
       "      <td>MARTINEZ ROJAS, ANTONIO</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>screenshot0006.JPEG</td>\n",
       "      <td>MARTINEZ ROJAS, ANTONIO</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>screenshot0007.JPEG</td>\n",
       "      <td>MARTINEZ ROJAS, ANTONIO</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>screenshot0011.JPEG</td>\n",
       "      <td>MARTINEZ ROJAS, ANTONIO</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>screenshot0012.JPEG</td>\n",
       "      <td>MAR</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>screenshot0013.JPEG</td>\n",
       "      <td>MASIA CARRION, LIONEL</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>screenshot0020.JPEG</td>\n",
       "      <td>MASI</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>screenshot0021.JPEG</td>\n",
       "      <td>MUNIZ CANALA, ANA</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>screenshot0022.JPEG</td>\n",
       "      <td>MUNIZ CANALA, ANA</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>screenshot0023.JPEG</td>\n",
       "      <td>MUNIZ CANALA, ANA</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>screenshot0027.JPEG</td>\n",
       "      <td>MUNIZ CANALA, ANA</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>screenshot0028.JPEG</td>\n",
       "      <td>MUN</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>screenshot0029.JPEG</td>\n",
       "      <td>BALVIN GUTIERREZ, JOSE</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>screenshot0036.JPEG</td>\n",
       "      <td>BALV</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>screenshot0047.JPEG</td>\n",
       "      <td>LOPEZ GARCIA, RAQUEL</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ocel:screenshot:name                   header  activity_label  process_id\n",
       "0   screenshot0004.JPEG                     LOPE               3           1\n",
       "1   screenshot0005.JPEG  MARTINEZ ROJAS, ANTONIO               6           1\n",
       "2   screenshot0006.JPEG  MARTINEZ ROJAS, ANTONIO               2           1\n",
       "3   screenshot0007.JPEG  MARTINEZ ROJAS, ANTONIO               6           1\n",
       "7   screenshot0011.JPEG  MARTINEZ ROJAS, ANTONIO               2           1\n",
       "8   screenshot0012.JPEG                      MAR               3           2\n",
       "9   screenshot0013.JPEG    MASIA CARRION, LIONEL               0           2\n",
       "16  screenshot0020.JPEG                     MASI               3           3\n",
       "17  screenshot0021.JPEG        MUNIZ CANALA, ANA               5           3\n",
       "18  screenshot0022.JPEG        MUNIZ CANALA, ANA               2           3\n",
       "19  screenshot0023.JPEG        MUNIZ CANALA, ANA               5           3\n",
       "23  screenshot0027.JPEG        MUNIZ CANALA, ANA               2           3\n",
       "24  screenshot0028.JPEG                      MUN               3           4\n",
       "25  screenshot0029.JPEG   BALVIN GUTIERREZ, JOSE               1           4\n",
       "32  screenshot0036.JPEG                     BALV               3           5\n",
       "33  screenshot0047.JPEG     LOPEZ GARCIA, RAQUEL               4           5"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[image_col, text_col, 'activity_label', 'process_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join('results', 'df.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminos_final = extraer_caminos(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminos_inicial_set = set(caminos_inicial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminos_final_set = set(caminos_final.apply(tuple))\n",
    "caminos_apriori_set = set(caminos_apriori_series.apply(tuple))\n",
    "\n",
    "caminos_nuevos = caminos_final_set - caminos_apriori_set\n",
    "caminos_no_descubiertos = caminos_apriori_set - caminos_final_set\n",
    "\n",
    "porcentaje_nuevos = (len(caminos_nuevos) / len(caminos_final_set)) * 100 if caminos_final_set else 0\n",
    "porcentaje_no_descubiertos = (len(caminos_no_descubiertos) / len(caminos_apriori_set)) * 100 if caminos_apriori_set else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caminos a priori: 4\n",
      "Caminos iniciales: 4\n",
      "Caminos finales: 4\n",
      "Porcentaje de nuevos caminos: 100.00%\n",
      "Caminos no descubiertos: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print('Caminos a priori:', len(caminos_apriori)) # Caminos óptimos de mi proceso\n",
    "print('Caminos iniciales:', len(caminos_inicial_set)) # Caminos obtenidos del primer modelos de datos\n",
    "print('Caminos finales:', len(caminos_final_set)) # Caminos obtenidos después de aplicar post-procesado (eliminar duplicados de actividades)\n",
    "print(f'Porcentaje de nuevos caminos: {porcentaje_nuevos:.2f}%') # Porcentaje de caminos que están presente en el modelo final pero no se encontraban en el modelo a priori\n",
    "print(f'Caminos no descubiertos: {porcentaje_no_descubiertos:.2f}%') # Porcentaje de caminos que estaban en el modelo a priori pero no se encontraron en el modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parámetros de la ejecución\n",
      "===========================\n",
      "Modelo empleado: clip\n",
      "Peso texto: 0.5\n",
      "Peso imagen: 0.5\n",
      "Rango de clústeres: (2, 11)\n",
      "Usar PCA: False\n",
      "Número de componentes PCA: 0.95\n",
      "\n",
      "Caminos a priori\n",
      "=================\n",
      "Caminos a priori: ((1, 0, 3, 2, 8, 4), (1, 0, 3, 2, 9), (1, 0, 3, 2, 6), (1, 0, 3, 2, 7))\n",
      "Caminos iniciales: {(3, 8, 6, 5, 9), (3, 0, 6, 5, 2), (3, 8, 6, 5, 7), (3, 0, 6, 5, 4, 1)}\n",
      "Caminos finales: {(3, 8, 6, 5, 9), (3, 0, 6, 5, 2), (3, 8, 6, 5, 7), (3, 0, 6, 5, 4, 1)}\n",
      "Porcentaje de nuevos caminos: 100.00%\n",
      "Caminos no descubiertos: 100.00%\n",
      "\n",
      "Métricas a nivel del proceso (PM4PY)\n",
      "=====================================\n",
      "Fitness: 1.0\n",
      "Precisión: 0.7837837837837838\n",
      "Generalización: 0.44038059222874415\n",
      "Simplicidad: 0.7391304347826086\n",
      "\n",
      "Métricas de clusterización\n",
      "===========================\n",
      "Clusterización: {'silhouette_score': 1.0, 'davies_bouldin_score': 0.0, 'calinski_harabasz_score': 1.0}\n"
     ]
    }
   ],
   "source": [
    "def print_with_separator(text, separator='='):\n",
    "    print(f\"{text}\\n{separator * len(text)}\")\n",
    "\n",
    "print_with_separator(\"\\nParámetros de la ejecución\")\n",
    "print(f'Modelo empleado: {model}')\n",
    "print(f'Peso texto: {text_weight}')\n",
    "print(f'Peso imagen: {image_weight}')\n",
    "print(f\"Rango de clústeres: {n_clusters_range}\")\n",
    "print(f\"Usar PCA: {use_pca}\")\n",
    "print(f\"Número de componentes PCA: {n_components}\")\n",
    "\n",
    "print_with_separator(\"\\nCaminos a priori\")\n",
    "print('Caminos a priori:', caminos_apriori)\n",
    "print('Caminos iniciales:', caminos_inicial_set)\n",
    "print('Caminos finales:', caminos_final_set)\n",
    "print(f'Porcentaje de nuevos caminos: {porcentaje_nuevos:.2f}%')\n",
    "print(f'Caminos no descubiertos: {porcentaje_no_descubiertos:.2f}%')\n",
    "\n",
    "print_with_separator(\"\\nMétricas a nivel del proceso (PM4PY)\")\n",
    "print(f\"Fitness: {fitness['averageFitness']}\")\n",
    "print(f\"Precisión: {precision}\")\n",
    "print(f\"Generalización: {generalization}\")\n",
    "print(f\"Simplicidad: {simplicity}\")\n",
    "\n",
    "print_with_separator(\"\\nMétricas de clusterización\")\n",
    "print(f'Clusterización: {optimal_metrics}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "informacion = f\"\"\"\n",
    "Parámetros de la ejecución\n",
    "Modelo empleado: {model}\n",
    "Peso texto: {text_weight}\n",
    "Peso imagen: {image_weight}\n",
    "Rango de clústeres: {n_clusters_range}\n",
    "Usar PCA: {use_pca}\n",
    "Número de componentes PCA: {n_components}\n",
    "\n",
    "Descubrimiento de caminos\n",
    "Caminos a priori: {caminos_apriori}\n",
    "Caminos iniciales: {caminos_inicial_set}\n",
    "Caminos finales: {caminos_final_set}\n",
    "Porcentaje de nuevos caminos: {porcentaje_nuevos:.2f}%\n",
    "Caminos no descubiertos: {porcentaje_no_descubiertos:.2f}%\n",
    "\n",
    "Métricas a nivel del proceso (PM4PY)\n",
    "Fitness: {fitness['averageFitness']}\n",
    "Precisión: {precision}\n",
    "Generalización: {generalization}\n",
    "Simplicidad: {simplicity}\n",
    "\n",
    "Métricas de clusterización\n",
    "Clusterización: {optimal_metrics}\n",
    "\"\"\"\n",
    "\n",
    "# Escribe la información en el archivo\n",
    "with open(\"results/execution.txt\", \"w\") as archivo:\n",
    "    archivo.write(informacion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lanzar / Guardar ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc_50 configuration\n",
    "caminos_apriori = {(5, 1, 2, 3, 4, 1, 0)}\n",
    "caminos_apriori_series = pd.Series(list(caminos_apriori))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoice configuration\n",
    "caminos_apriori = ((5,1,2,3,4))\n",
    "caminos_apriori_series = pd.Series(list(caminos_apriori))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoice customer path\n",
    "caminos_apriori = ((7,4,2,3,1,0), (7,4,6,5), (7,4,6,8))\n",
    "caminos_apriori_series = pd.Series(list(caminos_apriori))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'clip' #clip or vgg\n",
    "image_weight = 0.5\n",
    "text_weight = 0.5\n",
    "use_pca = False\n",
    "n_clusters_range = (2, 11)\n",
    "n_components = 0.95\n",
    "referencia = False\n",
    "asignacion = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10c75be197b4c049a53690cfb4ce7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ae120414b24d27bbdb66b2a6e64ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "computing precision with alignments, completed variants ::   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1e9109f1e44c4babd746b614af857b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = read_ui_log_as_dataframe(log_path)\n",
    "\n",
    "if model == 'clip':\n",
    "    df = extract_features_from_images(df, image_col, text_col, image_weight, text_weight, image_dir)\n",
    "elif model == 'vgg':\n",
    "    df = extract_features_from_VGG(df, image_dir, image_col)\n",
    "elif model == 'hash':\n",
    "    df = extract_features_andres(df, image_dir, image_col)\n",
    "\n",
    "df, clustering_scores, optimal_cluster, optimal_metrics = cluster_images(df, n_clusters_range, use_pca, n_components)\n",
    "\n",
    "if referencia:\n",
    "    centroides_referencia = calcular_centroides(np.array(df['combined_features']), df['activity_label'].values)\n",
    "\n",
    "if asignacion:\n",
    "    reasignar_clusters_en_df(df, centroides_referencia)\n",
    "    \n",
    "df = auto_process_id_assignment(df)\n",
    "caminos_inicial = extraer_caminos(df)\n",
    "df = eliminar_acciones_duplicadas(df, columna_label='activity_label')\n",
    "\n",
    "fitness, precision, generalization, simplicity = petri_net_process(df, timestamp_col)\n",
    "bpmn_process(df, timestamp_col)\n",
    "\n",
    "df.to_csv(os.path.join('results', 'df.csv'), index=False)\n",
    "\n",
    "caminos_final = extraer_caminos(df)\n",
    "caminos_inicial_set = set(caminos_inicial)\n",
    "\n",
    "caminos_final_set = set(caminos_final.apply(tuple))\n",
    "caminos_apriori_set = set(caminos_apriori_series.apply(tuple))\n",
    "\n",
    "caminos_nuevos = caminos_final_set - caminos_apriori_set\n",
    "caminos_no_descubiertos = caminos_apriori_set - caminos_final_set\n",
    "\n",
    "porcentaje_nuevos = (len(caminos_nuevos) / len(caminos_final_set)) * 100 if caminos_final_set else 0\n",
    "porcentaje_no_descubiertos = (len(caminos_no_descubiertos) / len(caminos_apriori_set)) * 100 if caminos_apriori_set else 0\n",
    "\n",
    "informacion = f\"\"\"\n",
    "Parámetros de la ejecución\n",
    "Modelo empleado: {model}\n",
    "Peso texto: {text_weight}\n",
    "Peso imagen: {image_weight}\n",
    "Rango de clústeres: {n_clusters_range}\n",
    "Usar PCA: {use_pca}\n",
    "Número de componentes PCA: {n_components}\n",
    "\n",
    "Descubrimiento de caminos\n",
    "Caminos a priori: {caminos_apriori}\n",
    "Caminos iniciales: {caminos_inicial_set}\n",
    "Caminos finales: {caminos_final_set}\n",
    "Porcentaje de nuevos caminos: {porcentaje_nuevos:.2f}%\n",
    "Caminos no descubiertos: {porcentaje_no_descubiertos:.2f}%\n",
    "\n",
    "Métricas a nivel del proceso (PM4PY)\n",
    "Fitness: {fitness['averageFitness']}\n",
    "Precisión: {precision}\n",
    "Generalización: {generalization}\n",
    "Simplicidad: {simplicity}\n",
    "\n",
    "Métricas de clusterización\n",
    "Clusterización: {optimal_metrics}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"results/execution.txt\", \"w\") as archivo:\n",
    "    archivo.write(informacion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los archivos de 'results' han sido copiados a 'executions\\exec_14'.\n"
     ]
    }
   ],
   "source": [
    "executions_dir = \"executions\"\n",
    "results_dir = \"results\"\n",
    "\n",
    "if not os.path.exists(executions_dir):\n",
    "    os.makedirs(executions_dir)\n",
    "\n",
    "existing_folders = [folder for folder in os.listdir(executions_dir) if folder.startswith('exec_')]\n",
    "if existing_folders:\n",
    "    highest_number = max([int(folder.split('_')[1]) for folder in existing_folders])\n",
    "    next_exec_number = highest_number + 1\n",
    "else:\n",
    "    next_exec_number = 1\n",
    "\n",
    "exec_subfolder = f\"exec_{next_exec_number}\"\n",
    "path_subfolder = os.path.join(executions_dir, exec_subfolder)\n",
    "os.makedirs(path_subfolder)\n",
    "\n",
    "for filename in os.listdir(results_dir):\n",
    "    source_file = os.path.join(results_dir, filename)\n",
    "    destination_file = os.path.join(path_subfolder, filename)\n",
    "    shutil.copy(source_file, destination_file)\n",
    "\n",
    "print(f\"Todos los archivos de '{results_dir}' han sido copiados a '{path_subfolder}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar variables globales\n",
    "current_cluster_images = []\n",
    "current_image_index = 0\n",
    "\n",
    "# Widgets\n",
    "cluster_selector = widgets.Dropdown(options=sorted(df['activity_label'].unique()), description='Filtra Cluster:')\n",
    "image_display = widgets.Output()\n",
    "thumbnails_display = widgets.Output(layout={'width': '100%', 'overflow': 'scroll'})\n",
    "image_counter = widgets.Label()\n",
    "assign_cluster_input = widgets.Text(value='', description='Asigna Cluster:')\n",
    "next_button = widgets.Button(description='Siguiente Imagen')\n",
    "prev_button = widgets.Button(description='Imagen Anterior')\n",
    "assign_button = widgets.Button(description='Asignar a Cluster')\n",
    "metrics_display = widgets.Label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_thumbnails(cluster):\n",
    "    \"\"\"Muestra las miniaturas de todas las imágenes del cluster seleccionado, incluyendo la etiqueta de activity_manual si existe.\"\"\"\n",
    "    global current_cluster_images\n",
    "    with thumbnails_display:\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(20, 3))\n",
    "        for idx, img_index in enumerate(current_cluster_images):\n",
    "            img_path = os.path.join('resources', 'sc_0_size50_Balanced', df.loc[img_index, 'Screenshot'])\n",
    "            if os.path.exists(img_path):\n",
    "                img = mpimg.imread(img_path)\n",
    "                plt.subplot(1, len(current_cluster_images), idx + 1)\n",
    "                plt.imshow(img)\n",
    "                # Verificar si la imagen tiene una etiqueta en activity_manual\n",
    "                manual_label = df.loc[img_index, 'activity_manual']\n",
    "                if pd.isna(manual_label) or manual_label == \"\":\n",
    "                    title = f'#{idx+1} - NA'\n",
    "                else:\n",
    "                    title = f'#{idx+1} - {manual_label}'\n",
    "                plt.title(title)\n",
    "                plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def update_image_counter():\n",
    "    \"\"\"Actualiza el contador de imágenes para mostrar la posición actual en el cluster.\"\"\"\n",
    "    image_counter.value = f'Imagen {current_image_index + 1} de {len(current_cluster_images)}'\n",
    "\n",
    "def display_current_image():\n",
    "    \"\"\"Muestra la imagen actual para la asignación de cluster.\"\"\"\n",
    "    global current_image_index\n",
    "    with image_display:\n",
    "        clear_output(wait=True)\n",
    "        if current_cluster_images:\n",
    "            img_path = os.path.join('resources', 'sc_0_size50_Balanced', df.loc[current_cluster_images[current_image_index], 'Screenshot'])\n",
    "            img = mpimg.imread(img_path)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "    update_image_counter()\n",
    "\n",
    "def on_cluster_selected(change):\n",
    "    \"\"\"Actualiza la lista de imágenes y muestra las miniaturas al seleccionar un cluster.\"\"\"\n",
    "    global current_cluster_images, current_image_index\n",
    "    current_cluster = change['new']\n",
    "    current_cluster_images = df[df['activity_label'] == current_cluster].index.tolist()\n",
    "    current_image_index = 0\n",
    "    display_thumbnails(current_cluster)\n",
    "    display_current_image()\n",
    "\n",
    "def on_next_button_clicked(b):\n",
    "    \"\"\"Navega a la siguiente imagen del cluster.\"\"\"\n",
    "    global current_image_index\n",
    "    if current_image_index < len(current_cluster_images) - 1:\n",
    "        current_image_index += 1\n",
    "    else:\n",
    "        current_image_index = 0 \n",
    "    display_current_image()\n",
    "\n",
    "def on_prev_button_clicked(b):\n",
    "    \"\"\"Navega a la imagen anterior del cluster.\"\"\"\n",
    "    global current_image_index\n",
    "    if current_image_index > 0:\n",
    "        current_image_index -= 1\n",
    "    else:\n",
    "        current_image_index = len(current_cluster_images) - 1  # Opcional: ir al final si se desea un ciclo continuo\n",
    "    display_current_image()\n",
    "\n",
    "def on_assign_button_clicked(b):\n",
    "    global current_cluster_images, current_image_index\n",
    "    df.at[current_cluster_images[current_image_index], 'activity_manual'] = assign_cluster_input.value\n",
    "    display_thumbnails(cluster_selector.value)\n",
    "    \n",
    "    # Calcular métricas después de cada asignación\n",
    "    precision_actual = calcular_metricas()\n",
    "    metrics_display.value = f'Precisión actual: {precision_actual:.2f}%'\n",
    "\n",
    "def calcular_metricas():\n",
    "    mapeo_manual_a_numerico = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9}\n",
    "    df['manual_numerico'] = df['activity_manual'].map(mapeo_manual_a_numerico)\n",
    "    df['coincidencia'] = df['manual_numerico'] == df['activity_label']\n",
    "    precision = df['coincidencia'].mean() * 100\n",
    "    \n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f02c1794154127a35bfff4301c9df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Filtra Cluster:', index=4, options=(0, 1, 2, 3, 4), value=4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50698e5a43874c088fa6198b8e14048b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(overflow='scroll', width='100%'), outputs=({'traceback': ['\\x1b[1;31m--------------------…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798ce96d71f647488ae6a29814113ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(outputs=({'output_type': 'display_data', 'data': {'text/plain': '<Figure size 2000x300 with 1 Axes>', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8260fbdb2f4613a9a27c5607fed51f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Imagen 1 de 8')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dac3b767a454aba8b29a1fdb8bf798c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0135af0b39c4c418b517057d68a52ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Imagen Anterior', style=ButtonStyle()), Button(description='Siguiente Image…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Conexión de widgets a los botones\n",
    "cluster_selector.observe(on_cluster_selected, names='value')\n",
    "next_button.on_click(on_next_button_clicked)\n",
    "prev_button.on_click(on_prev_button_clicked)\n",
    "assign_button.on_click(on_assign_button_clicked)\n",
    "\n",
    "# Mostrar los widgets\n",
    "display(cluster_selector)\n",
    "display(thumbnails_display)\n",
    "display(image_display)\n",
    "display(image_counter)\n",
    "display(metrics_display)\n",
    "display(widgets.HBox([prev_button, next_button, assign_cluster_input, assign_button]))\n",
    "\n",
    "# Inicializar la visualización con el primer cluster\n",
    "if df['activity_label'].unique().size > 0:\n",
    "    current_cluster = cluster_selector.options[0]\n",
    "    on_cluster_selected({'new': current_cluster})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labbing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['activity_manual'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('resources/sc_0_size50_Balanced/editar.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "petri_net_process(read_ui_log_as_dataframe('resources/sc_0_size50_Balanced/editar.csv'))\n",
    "bpmn_process(read_ui_log_as_dataframe('resources/sc_0_size50_Balanced/editar.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
