{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLIP Process Discovery Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import GridBox, Layout\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# TensorFlow related imports\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# PM4Py related imports\n",
    "import pm4py\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "from pm4py.objects.conversion.process_tree import converter as pt_converter\n",
    "from pm4py.visualization.petri_net import visualizer as pn_visualizer\n",
    "from pm4py.visualization.bpmn import visualizer as bpmn_visualizer\n",
    "from pm4py.objects.bpmn.exporter import exporter as bpmn_exporter\n",
    "from pm4py.algo.evaluation.replay_fitness import algorithm as replay_fitness_evaluator\n",
    "from pm4py.algo.evaluation.precision import algorithm as precision_evaluator\n",
    "from pm4py.algo.evaluation.generalization import algorithm as generalization_evaluator\n",
    "from pm4py.algo.evaluation.simplicity import algorithm as simplicity_evaluator\n",
    "from transformers import CLIPModel, CLIPProcessor, CLIPTokenizer\n",
    "\n",
    "import gc\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura fichero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ui_log_as_dataframe(log_path):\n",
    "  return pd.read_csv(log_path, sep=\";\")#, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_images(df, image_col, text_col, image_weight, text_weight, img_dir):\n",
    "    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "    combined_features = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        text = row[text_col]\n",
    "        # Usa os.path.join para construir la ruta completa de la imagen.\n",
    "        image_path = os.path.join(img_dir, row[image_col])\n",
    "        \n",
    "        # Asegúrate de que la imagen exista, de lo contrario lanza un error.\n",
    "        if not os.path.exists(image_path):\n",
    "            raise ValueError(f\"La imagen no existe en {image_path}\")\n",
    "\n",
    "        # Abre la imagen usando la ruta completa.\n",
    "        image = Image.open(image_path)\n",
    "        inputs = processor(text=[text], images=image, return_tensors=\"pt\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        image_features = outputs.image_embeds.cpu().numpy().flatten() * image_weight\n",
    "        text_features = outputs.text_embeds.cpu().numpy().flatten() * text_weight\n",
    "        \n",
    "        combined_feature = np.hstack((image_features, text_features))\n",
    "        combined_features.append(combined_feature)\n",
    "\n",
    "    df['combined_features'] = combined_features\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_images_with_tokenizer(df, image_col, text_col, image_weight, text_weight, img_dir, header_txt=False, text_path_col=\"header_txt\"):\n",
    "    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "    combined_features = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if header_txt:\n",
    "            txt_path = os.path.join(\"logs/invoice_def\", \"ocr_results\", row[text_path_col])\n",
    "            if not os.path.exists(txt_path):\n",
    "                raise FileNotFoundError(f\"El archivo de texto no existe: {txt_path}\")\n",
    "            with open(txt_path, 'r') as file:\n",
    "                text = file.read()\n",
    "        else:\n",
    "            text = row[text_col]\n",
    "\n",
    "        # Tokenizar el texto\n",
    "        input_ids = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "        \n",
    "        # Construye la ruta completa de la imagen y asegura que exista.\n",
    "        image_path = os.path.join(img_dir, row[image_col])\n",
    "        if not os.path.exists(image_path):\n",
    "            raise ValueError(f\"La imagen no existe en {image_path}\")\n",
    "\n",
    "        # Abre la imagen y la procesa con el modelo CLIP\n",
    "        image = Image.open(image_path)\n",
    "        image_inputs = processor(images=[image], return_tensors=\"pt\")\n",
    "\n",
    "        # Combina las entradas de texto e imagen y pasarlo al modelo\n",
    "        inputs = {'input_ids': input_ids['input_ids'], 'attention_mask': input_ids['attention_mask'], 'pixel_values': image_inputs['pixel_values']}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        image_features = outputs.image_embeds.cpu().numpy().flatten() * image_weight\n",
    "        text_features = outputs.text_embeds.cpu().numpy().flatten() * text_weight\n",
    "        combined_feature = np.hstack((image_features, text_features))\n",
    "        combined_features.append(combined_feature)\n",
    "\n",
    "    df['combined_features'] = combined_features\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_images(df, n_clusters_range, use_pca, n_components):\n",
    "    features = np.array(df['combined_features'].tolist())\n",
    "    \n",
    "    if use_pca:\n",
    "        pca = PCA(n_components=n_components)\n",
    "        features = pca.fit_transform(features)\n",
    "        print(f\"PCA aplicado: {features.shape[1]} componentes retenidos\")\n",
    "\n",
    "    clustering_scores = {\n",
    "        'n_clusters': [],\n",
    "        'silhouette_score': [],\n",
    "        'davies_bouldin_score': [],\n",
    "        'calinski_harabasz_score': []\n",
    "    }\n",
    "\n",
    "    for k in range(*n_clusters_range):\n",
    "        clustering = AgglomerativeClustering(n_clusters=k).fit(features)\n",
    "        labels = clustering.labels_\n",
    "\n",
    "        clustering_scores['n_clusters'].append(k)\n",
    "        clustering_scores['silhouette_score'].append(silhouette_score(features, labels))\n",
    "        clustering_scores['davies_bouldin_score'].append(davies_bouldin_score(features, labels))\n",
    "        clustering_scores['calinski_harabasz_score'].append(calinski_harabasz_score(features, labels))\n",
    "\n",
    "    # Encuentra el índice del número óptimo de clústeres basado en la mejor puntuación Silhouette\n",
    "    optimal_index = np.argmax(clustering_scores['silhouette_score'])\n",
    "    optimal_clusters = clustering_scores['n_clusters'][optimal_index]\n",
    "\n",
    "    # Ejecutar el clustering con el número óptimo de clústeres\n",
    "    best_clustering = AgglomerativeClustering(n_clusters=optimal_clusters).fit(features)\n",
    "    df['activity_label'] = best_clustering.labels_\n",
    "\n",
    "    # Obtener las métricas para el número óptimo de clústeres\n",
    "    optimal_metrics = {\n",
    "        'silhouette_score': clustering_scores['silhouette_score'][optimal_index],\n",
    "        'davies_bouldin_score': clustering_scores['davies_bouldin_score'][optimal_index],\n",
    "        'calinski_harabasz_score': clustering_scores['calinski_harabasz_score'][optimal_index]\n",
    "    }\n",
    "\n",
    "    return df, clustering_scores, optimal_clusters, optimal_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_caminos(df):\n",
    "    caminos = df.groupby('process_id')['activity_label'].apply(tuple)\n",
    "    return caminos\n",
    "\n",
    "def calcular_metricas(caminos_logs, caminos_apriori, caminos_inicial, caminos_final):\n",
    "    caminos_logs_set = set(caminos_logs)\n",
    "    caminos_apriori_set = set(caminos_apriori)\n",
    "    caminos_inicial_set = set(caminos_inicial)\n",
    "    caminos_final_set = set(caminos_final)\n",
    "    \n",
    "    # Calcular las métricas\n",
    "    num_paths_apriori = len(caminos_apriori_set)\n",
    "    num_paths_inicial = len(caminos_inicial_set)\n",
    "    num_paths_final = len(caminos_final_set)\n",
    "    \n",
    "    # Porcentajes de nuevos caminos y caminos no descubiertos\n",
    "    new_paths = caminos_final_set - caminos_apriori_set\n",
    "    percent_new = len(new_paths) / num_paths_final if num_paths_final else 0\n",
    "    \n",
    "    non_discovered_paths = caminos_apriori_set - caminos_final_set\n",
    "    percent_non_discovered = len(non_discovered_paths) / num_paths_apriori if num_paths_apriori else 0\n",
    "    \n",
    "    return {\n",
    "        'num_paths_apriori': num_paths_apriori,\n",
    "        'num_paths_inicial': num_paths_inicial,\n",
    "        'num_paths_final': num_paths_final,\n",
    "        'percent_new': percent_new * 100,\n",
    "        'percent_non_discovered': percent_non_discovered * 100\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case id allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_process_id_assignment(df):\n",
    "    activity_inicial = df['activity_label'].iloc[0]\n",
    "    process_id = 1\n",
    "    process_ids = [process_id]  \n",
    "    for index, row in df.iterrows():\n",
    "        if index != 0:  \n",
    "            if row['activity_label'] == activity_inicial:\n",
    "                process_id += 1\n",
    "            process_ids.append(process_id)\n",
    "        else:\n",
    "            continue\n",
    "    df['process_id'] = process_ids\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_acciones_duplicadas(df, columna_label='activity_label'):\n",
    "    while True:\n",
    "        mascaras_para_eliminar = df[columna_label].eq(df[columna_label].shift())\n",
    "        if mascaras_para_eliminar.sum() == 0:\n",
    "            break\n",
    "        df = df[~mascaras_para_eliminar].reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bpmn / Petrinet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def petri_net_process(df, timestamp_col):\n",
    "    # DataFrame To EventLog\n",
    "    formatted_df = pm4py.format_dataframe(df, case_id='process_id', activity_key='activity_label', timestamp_key=timestamp_col)\n",
    "    event_log = pm4py.convert_to_event_log(formatted_df)\n",
    "\n",
    "    # Descubrimiento del árbol del proceso\n",
    "    process_tree = inductive_miner.apply(event_log)\n",
    "    net, initial_marking, final_marking = pm4py.convert_to_petri_net(process_tree)\n",
    "\n",
    "    # Métricas\n",
    "    fitness = replay_fitness_evaluator.apply(event_log, net, initial_marking, final_marking)\n",
    "    precision = precision_evaluator.apply(event_log, net, initial_marking, final_marking)\n",
    "    generalization = generalization_evaluator.apply(event_log, net, initial_marking, final_marking)\n",
    "    simplicity = simplicity_evaluator.apply(net)\n",
    "\n",
    "    # Guardar resultados\n",
    "    dot = pn_visualizer.apply(net, initial_marking, final_marking)\n",
    "    dot_path = os.path.join('results', 'pn.dot')\n",
    "    with open(dot_path, 'w') as f:\n",
    "        f.write(dot.source)\n",
    "\n",
    "    return fitness, precision, generalization, simplicity\n",
    "\n",
    "def bpmn_process(df, timestamp_col):\n",
    "    # DataFrame To EventLog\n",
    "    formatted_df = pm4py.format_dataframe(df, case_id='process_id', activity_key='activity_label', timestamp_key=timestamp_col)\n",
    "    event_log = pm4py.convert_to_event_log(formatted_df)\n",
    "\n",
    "    # Descubrimiento del modelo BPMN\n",
    "    bpmn_model = pm4py.discover_bpmn_inductive(event_log)\n",
    "\n",
    "    # Guardar resultados\n",
    "    dot = bpmn_visualizer.apply(bpmn_model)\n",
    "    dot_path = os.path.join('results', 'bpmn.dot')\n",
    "    with open(dot_path, 'w') as f:\n",
    "        f.write(dot.source)\n",
    "    bpmn_exporter.apply(bpmn_model, os.path.join('results', 'bpmn.bpmn'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoice def (+1 path 'customer path')\n",
    "log_path = 'logs/invoice_def/log.csv'\n",
    "image_col = 'screenshot'\n",
    "image_dir = 'resources/invoice_def'\n",
    "text_col = 'header'\n",
    "timestamp_col = 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SC50_Rebuild\n",
    "log_path = 'logs/SC50_Rebuild/fake.csv'\n",
    "image_col = 'screenshot'\n",
    "image_dir = 'resources/SC50_Rebuild'\n",
    "text_col = 'header'\n",
    "timestamp_col = 'timestamp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lanzar / Guardar ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoice customer path\n",
    "caminos_apriori = ((7,4,2,3,1,0), (7,4,6,5), (7,4,6,8))\n",
    "caminos_apriori_series = pd.Series(list(caminos_apriori))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraciones iniciales\n",
    "model = 'clip'\n",
    "n_clusters_range = (2, 11)\n",
    "n_components = 0.95\n",
    "use_pca = False\n",
    "tokeniza = False #¿Tokenizamos?\n",
    "header_txt = False #¿Usamos el texto completo?\n",
    "\n",
    "# Directorio principal para los casos de estudio\n",
    "case_study_name = \"sc50_rebuild_text_token\" \n",
    "root_dir = os.path.join(\"executions\", case_study_name)\n",
    "os.makedirs(root_dir, exist_ok=True)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Información de las ejecuciones a realizar\n",
    "executions = [\n",
    "    {'exec': 1, 'image_weight': 1, 'text_weight': 0},\n",
    "    {'exec': 2, 'image_weight': 0.8, 'text_weight': 0.2},\n",
    "    {'exec': 3, 'image_weight': 0.6, 'text_weight': 0.4},\n",
    "    {'exec': 4, 'image_weight': 0.5, 'text_weight': 0.5},\n",
    "    {'exec': 5, 'image_weight': 0.4, 'text_weight': 0.6},\n",
    "    {'exec': 6, 'image_weight': 0.2, 'text_weight': 0.8},\n",
    "    {'exec': 7, 'image_weight': 0, 'text_weight': 1}\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overwrite_csv(df, file_path):\n",
    "    \"\"\"Escribe un DataFrame a un archivo CSV, sobrescribiendo el archivo existente.\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "        df.to_csv(file_path, index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al escribir el archivo CSV: {e}\")\n",
    "\n",
    "def move_and_overwrite(source, destination):\n",
    "    \"\"\"Mueve un archivo de una ubicación a otra y lo sobrescribe si ya existe.\"\"\"\n",
    "    if os.path.exists(destination):\n",
    "        os.remove(destination)\n",
    "    shutil.move(source, destination)\n",
    "    \n",
    "def clear_caches():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def load_fresh_data():\n",
    "    return read_ui_log_as_dataframe(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d04da5d7a904d7dbddbee24b0c04a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02769019133b42deacbb267793b23cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "computing precision with alignments, completed variants ::   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd0b5f2183a4e959169c587eb78055e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc08496ad32f4b8b9973544c3dd9b775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b364374414473ca59eddc9b6786784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "computing precision with alignments, completed variants ::   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a25629388640f889feeaac9caaa988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ae40460a0941bf917e909136e65006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304e2533859a413caf1e3c73705e475a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "computing precision with alignments, completed variants ::   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2a53b4f3504fb88b65d0c1f2281b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99cc6b5cff5546d1b0bd3ec353c16e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e489a0c7b05245ae819b1329e21421f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "computing precision with alignments, completed variants ::   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0507ae53a40e4633b8fc475e092b8f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8570b56ec3e406d9c144975ffc22dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f275358a544bad9f3ea6e5ec70436c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "computing precision with alignments, completed variants ::   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdbdeb90dd654c1f9e5c187754107e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0571981adee4a1d825b2e6283a2c794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497047eade4742f7aad8a32de4135503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "computing precision with alignments, completed variants ::   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f134eb6a988c4a5ab2330b4aa3099956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fbaddcdb6344668cbce0fd87401967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e19166accb64fe3b36ee00a708e9bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "computing precision with alignments, completed variants ::   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35064a2ea25145a6b6ac6bbc398358e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for exec in executions:\n",
    "\n",
    "    df = read_ui_log_as_dataframe(log_path)\n",
    "    clear_caches()  \n",
    "\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "        \n",
    "    exec_dir = f\"{case_study_name}_{exec['image_weight']}_{exec['text_weight']}\"\n",
    "    exec_path = os.path.join(root_dir, exec_dir)\n",
    "    os.makedirs(exec_path, exist_ok=True)\n",
    "\n",
    "    image_weight = exec['image_weight']\n",
    "    text_weight = exec['text_weight']\n",
    "    \n",
    "    if tokeniza:\n",
    "        df = extract_features_from_images_with_tokenizer(df, image_col, text_col, image_weight, text_weight, image_dir, header_txt, text_path_col='header_txt')\n",
    "    else:\n",
    "        df = extract_features_from_images(df, image_col, text_col, image_weight, text_weight, image_dir)\n",
    "    \n",
    "    df, clustering_scores, optimal_clusters, optimal_metrics = cluster_images(df, n_clusters_range, use_pca, n_components)\n",
    "\n",
    "    df = auto_process_id_assignment(df)\n",
    "    caminos_inicial = extraer_caminos(df)\n",
    "    df = eliminar_acciones_duplicadas(df, columna_label='activity_label')\n",
    "\n",
    "    fitness, precision, generalization, simplicity = petri_net_process(df, timestamp_col)\n",
    "    bpmn_process(df, timestamp_col)\n",
    "\n",
    "    df.to_csv(os.path.join(exec_path, 'df.csv'), index=False)\n",
    "    move_and_overwrite('results/pn.dot', os.path.join(exec_path, 'pn.dot'))\n",
    "    move_and_overwrite('results/bpmn.dot', os.path.join(exec_path, 'bpmn.dot'))\n",
    "    move_and_overwrite('results/bpmn.bpmn', os.path.join(exec_path, 'bpmn.bpmn'))\n",
    "\n",
    "    caminos_final = extraer_caminos(df)\n",
    "    caminos_inicial_set = set(caminos_inicial)\n",
    "    caminos_final_set = set(caminos_final.apply(tuple))\n",
    "    caminos_apriori_set = set(caminos_apriori_series.apply(tuple))\n",
    "    caminos_nuevos = caminos_final_set - caminos_apriori_set\n",
    "    caminos_no_descubiertos = caminos_apriori_set - caminos_final_set\n",
    "    porcentaje_nuevos = (len(caminos_nuevos) / len(caminos_final_set)) * 100 if caminos_final_set else 0\n",
    "    porcentaje_no_descubiertos = (len(caminos_no_descubiertos) / len(caminos_apriori_set)) * 100 if caminos_apriori_set else 0\n",
    "\n",
    "    with open(os.path.join(exec_path, 'caminos_stats.txt'), 'w') as file:\n",
    "        file.write(f\"Descubrimiento de caminos\\n\")\n",
    "        file.write(f\"Pesos utilizados - Peso de imagen: {image_weight}, Peso de texto: {text_weight}\\n\")\n",
    "        file.write(f\"Caminos a priori: {caminos_apriori}\\n\")\n",
    "        file.write(f\"Caminos iniciales: {caminos_inicial_set}\\n\")\n",
    "        file.write(f\"Caminos finales: {caminos_final_set}\\n\")\n",
    "        file.write(f\"Porcentaje de nuevos caminos: {porcentaje_nuevos:.2f}%\\n\")\n",
    "        file.write(f\"Caminos no descubiertos: {porcentaje_no_descubiertos:.2f}%\\n\")\n",
    "\n",
    "\n",
    "    results.append({\n",
    "        'exec': exec['exec'],\n",
    "        'image_weight': image_weight,\n",
    "        'text_weight': text_weight,\n",
    "        'new%': porcentaje_nuevos,\n",
    "        'pathNotDisc%': porcentaje_no_descubiertos,\n",
    "        'Silhouette': optimal_metrics['silhouette_score'],\n",
    "        'Davies-Bouldin': optimal_metrics['davies_bouldin_score'],\n",
    "        'Calinski-Harabasz': optimal_metrics['calinski_harabasz_score'],\n",
    "        'Fitness': fitness,\n",
    "        'Precision': precision,\n",
    "        'Generalization': generalization,\n",
    "        'Simplicity': simplicity\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "overwrite_csv(results_df, os.path.join(root_dir, 'resultados.csv'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
